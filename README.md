## üéØObjetivo
Este projeto visa avaliar o desempenho dos trainees do DataLab-UFU ap√≥s a conclus√£o das trilhas obrigat√≥rias do DataCamp, identificando lacunas de aprendizado e oportunidades de melhoria t√©cnica.

## üìäInterpreta√ß√£o das estat√≠sticas descritivas

N√£o temos diferen√ßas significativas entre as estat√≠sticas descritivas calculadas no Excel contra as calculadas no Python.

A maior nota foi 98 e a menor 45, uma amplitude de 53 pontos.

Como a mediana (74.5) √© ligeiramente maior que a m√©dia (73.67), temos uma leve assimetria √† esquerda indicando que h√°  algumas notas mais baixas (como o m√≠nimo de 45) que est√£o puxando a m√©dia para baixo.
Al√©m disso, h√° um desvio de aproximadamente 14 pontos que sugere uma turma heterog√™nea, ou seja, existem alunos que est√£o indo muito bem e os que est√£o com dificuldade.

De modo geral √© uma turma com bom desempenho geral, j√° que a maioria (75%) tirou acima de 63 pontos.
![](https://github.com/gustavodrst/imagens/blob/main/gr%C3%A1ficos_desafio_trainee.png)

## üßÆInterpreta√ß√£o das Correla√ß√µes 
### Correla√ß√µes Positivas Fortes (Amarelo)
![](https://github.com/gustavodrst/imagens/blob/main/correla%C3%A7%C3%A3o_desafio_trainee.png)

Quando uma vari√°vel aumenta, a outra tamb√©m aumenta quase na mesma propor√ß√£o.

Horas de Estudo X Nota Final (Correla√ß√£o = 1): estas vari√°veis apresentam uma correla√ß√£o positiva perfeita. Indicando que, quanto mais tempo o aluno dedica ao estudo, maior √© sua nota final.

Aulas Assistidas X Nota Final (Correla√ß√£o = 0,99): estas vari√°veis apresentam uma correla√ß√£o quase perfeita. Sugerindo que a presen√ßa e participa√ß√£o nas aulas est√£o diretamente ligadas a uma maior nota final.

## üìãInterpreta√ß√£o teste de Hip√≥tese
A escolha de dividir os alunos exatamente em "At√© 10h" e "Mais de 10h" foi feita para transformar uma vari√°vel cont√≠nua (horas_estudo) em uma vari√°vel categ√≥rica bin√°ria(at√©_10h e mais_10h), permitindo a compara√ß√£o de m√©dias entre dois grupos distintos.

Al√©m disso, chegampos ao resultado de que rejeitamos a Hip√≥tese Nula. Pois h√° evid√™ncias(p-valor<0.05) de que estudar mais de 10h aumenta a nota.

## üìàInterprete√ß√£o da Regress√£o
$\textbf{Mean Square Error (MSE) - Erro Quadr√°tico M√©dio:}$ √â a m√©dia dos quadrados dos erros. O erro √© a diferen√ßa entre o valor real ($y$) e o valor previsto ($\hat{y}$) pelo modelo.

Sendo utilizado para medir o qu√£o pr√≥ximos os valores previstos est√£o dos reais. Por elevar o erro ao quadrado, o MSE penaliza severamente erros grandes, tornando-o ideal se voc√™ quer evitar grandes desvios a qualquer custo.

$$\text{F√≥rmula:}$$ $$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$


$\textbf{Mean Absolute Error (MAE) - Erro Absoluto M√©dio:}$ √â a m√©dia das diferen√ßas absolutas entre os valores reais e previstos. 

Esta m√©trica fornece uma medida linear da magnitude do erro em uma escala que √© f√°cil de interpretar (na mesma unidade dos dados originais). Ao contr√°rio do MSE, ele n√£o penaliza tanto os outliers, tratando todos os erros de forma proporcional.

$$\text{F√≥rmula:}$$ $$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

$\textbf{R2 Score (Coeficiente de Determina√ß√£o):}$ √â uma m√©trica estat√≠stica que representa a porcentagem da vari√¢ncia da vari√°vel dependente que √© explicada pelo modelo, sendo utilizado para verificar a qualidade do ajuste. 
$$\text{F√≥rmula:}$$ $$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$$
Onde $SS_{res}$ √© a soma dos quadrados dos res√≠duos e $SS_{tot}$ √© a soma total dos quadrados

$\textbf{Como essas m√©tricas avaliam o desempenho?}$ 

Tais m√©tricas fornecem um diagn√≥stico do modelo

MSE/MAE baixos: Indicam que o modelo est√° errando pouco. Se o MSE estiver muito maior que o MAE, voc√™ sabe que tem alguns erros muito grandes (outliers) incomodando o modelo.

R2 Score alto: Indica que o modelo captura bem a tend√™ncia dos dados. Se o seu $R^2$ for baixo, a sua linha de regress√£o n√£o est√° conseguindo "explicar" o que acontece com os dados.

$\textbf{Divis√£o de dados:}$

Ao usar a fun√ß√£o train_test_split, dividimos o dataset em quatro partes:

x_train: As caracter√≠sticas que o modelo usar√° para aprender.

y_train: As respostas corretas que o modelo usa para ajustar seus par√¢metros.

x_test: Dados novos que o modelo nunca viu, usados para fazer previs√µes ap√≥s o treino.

y_test: As respostas reais do teste, usadas para comparar com as previs√µes e calcular o MSE, MAE e $R^2$.

E a fun√ß√£o train_test_split realiza essa divis√£o para evitar o Overfitting (sobreajuste). Se testarmos o modelo com os mesmos dados que usamos para trein√°-lo, ele pode simplesmente decorar os dados em vez de aprender a l√≥gica por tr√°s deles.

Dividir os dados nos permite simular o mundo real: treinando o modelo e verificamos se ele consegue prever com precis√£o.
